{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_path):\n",
    "    data = pickle.load(open(data_path, 'rb'))\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitted_patient_dict = load_data(\"/home/jl5307/current_research/AMD_prediction/img_data/data_dictionary/splitted_patient_dict.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_splitted_patient_verification_data_dict(splitted_patient_dict):\n",
    "\n",
    "    train_set = splitted_patient_dict[\"train_set\"]\n",
    "    validation_set = splitted_patient_dict[\"validation_set\"]\n",
    "    test_set = splitted_patient_dict[\"test_set\"]\n",
    "    \n",
    "    train_eye_dict = dict()\n",
    "    validation_eye_dict = dict()\n",
    "    test_eye_dict = dict()\n",
    "    \n",
    "    train_pid_list = []\n",
    "    train_year_list = []\n",
    "    train_eye_list = []\n",
    "    train_label_list = []\n",
    "    train_score_list = []\n",
    "    \n",
    "    validation_pid_list = []\n",
    "    validation_year_list = []\n",
    "    validation_eye_list = []\n",
    "    validation_label_list = []\n",
    "    validation_score_list = []\n",
    "\n",
    "    test_pid_list = []\n",
    "    test_year_list = []\n",
    "    test_eye_list = []\n",
    "    test_label_list = []\n",
    "    test_score_list = []\n",
    "    \n",
    "    # train set\n",
    "    for pid, value in train_set.items():\n",
    "        \n",
    "        re_year = np.array(value[\"re\"][\"re_year\"])\n",
    "        re_img_list = value[\"re\"][\"re_img\"]\n",
    "        re_severe_score = value[\"re\"][\"re_severe_score\"]\n",
    "        re_late_amd = np.array(value[\"re\"][\"re_late_amd\"])\n",
    "        \n",
    "        if len(re_img_list) != len(re_late_amd):\n",
    "            raise ValueError(\"the length of img_list and label_list must be the same\")\n",
    "        \n",
    "        train_pid_list.append(pid+\"_re\")\n",
    "        train_year_list.append(list(re_year))\n",
    "        train_eye_list.append(re_img_list)\n",
    "        train_label_list.append(re_late_amd)\n",
    "        train_score_list.append(re_severe_score)\n",
    "        \n",
    "        le_year = np.array(value[\"le\"][\"le_year\"])\n",
    "        le_img_list = value[\"le\"][\"le_img\"]\n",
    "        le_severe_score = value[\"le\"][\"le_severe_score\"]\n",
    "        le_late_amd = np.array(value[\"le\"][\"le_late_amd\"])\n",
    "        \n",
    "        if len(le_img_list) != len(le_late_amd):\n",
    "            raise ValueError(\"the length of img_list and label_list must be the same\")\n",
    "            \n",
    "        train_pid_list.append(pid+\"_le\")\n",
    "        train_year_list.append(list(le_year))\n",
    "        train_eye_list.append(le_img_list)\n",
    "        train_label_list.append(le_late_amd)\n",
    "        train_score_list.append(le_severe_score)\n",
    "    \n",
    "    train_eye_dict[\"pid_list\"] = train_pid_list\n",
    "    train_eye_dict[\"year_list\"] = train_year_list\n",
    "    train_eye_dict[\"eye_list\"] = train_eye_list\n",
    "    train_eye_dict[\"label_list\"] = train_label_list\n",
    "    train_eye_dict[\"score_list\"] = train_score_list\n",
    "        \n",
    "    # validation set\n",
    "    for pid, value in validation_set.items():\n",
    "        \n",
    "        re_year = np.array(value[\"re\"][\"re_year\"])\n",
    "        re_img_list = value[\"re\"][\"re_img\"]\n",
    "        re_severe_score = value[\"re\"][\"re_severe_score\"]\n",
    "        re_late_amd = np.array(value[\"re\"][\"re_late_amd\"])\n",
    "        \n",
    "        if len(re_img_list) != len(re_late_amd):\n",
    "            raise ValueError(\"the length of img_list and label_list must be the same\")\n",
    "        \n",
    "        validation_pid_list.append(pid+\"_re\")\n",
    "        validation_year_list.append(list(re_year))\n",
    "        validation_eye_list.append(re_img_list)\n",
    "        validation_label_list.append(re_late_amd)\n",
    "        validation_score_list.append(re_severe_score)\n",
    "        \n",
    "        le_year = np.array(value[\"le\"][\"le_year\"])\n",
    "        le_img_list = value[\"le\"][\"le_img\"]\n",
    "        le_severe_score = value[\"le\"][\"le_severe_score\"]\n",
    "        le_late_amd = np.array(value[\"le\"][\"le_late_amd\"])\n",
    "        \n",
    "        if len(le_img_list) != len(le_late_amd):\n",
    "            raise ValueError(\"the length of img_list and label_list must be the same\")\n",
    "            \n",
    "        validation_pid_list.append(pid+\"_le\")\n",
    "        validation_year_list.append(list(le_year))\n",
    "        validation_eye_list.append(le_img_list)\n",
    "        validation_label_list.append(le_late_amd)\n",
    "        validation_score_list.append(le_severe_score)\n",
    "    \n",
    "    validation_eye_dict[\"pid_list\"] = validation_pid_list\n",
    "    validation_eye_dict[\"year_list\"] = validation_year_list\n",
    "    validation_eye_dict[\"eye_list\"] = validation_eye_list\n",
    "    validation_eye_dict[\"label_list\"] = validation_label_list\n",
    "    validation_eye_dict[\"score_list\"] = validation_score_list\n",
    "    \n",
    "    # test set\n",
    "    for pid, value in test_set.items():\n",
    "        \n",
    "        re_year = np.array(value[\"re\"][\"re_year\"])\n",
    "        re_img_list = value[\"re\"][\"re_img\"]\n",
    "        re_severe_score = value[\"re\"][\"re_severe_score\"]\n",
    "        re_late_amd = np.array(value[\"re\"][\"re_late_amd\"])\n",
    "        \n",
    "        if len(re_img_list) != len(re_late_amd):\n",
    "            raise ValueError(\"the length of img_list and label_list must be the same\")\n",
    "        \n",
    "        test_pid_list.append(pid+\"_re\")\n",
    "        test_year_list.append(list(re_year))\n",
    "        test_eye_list.append(re_img_list)\n",
    "        test_label_list.append(re_late_amd)\n",
    "        test_score_list.append(re_severe_score)\n",
    "        \n",
    "        le_year = np.array(value[\"le\"][\"le_year\"])\n",
    "        le_img_list = value[\"le\"][\"le_img\"]\n",
    "        le_severe_score = value[\"le\"][\"le_severe_score\"]\n",
    "        le_late_amd = np.array(value[\"le\"][\"le_late_amd\"])\n",
    "        \n",
    "        if len(le_img_list) != len(le_late_amd):\n",
    "            raise ValueError(\"the length of img_list and label_list must be the same\")\n",
    "            \n",
    "        test_pid_list.append(pid+\"_le\")\n",
    "        test_year_list.append(list(le_year))\n",
    "        test_eye_list.append(le_img_list)\n",
    "        test_label_list.append(le_late_amd)\n",
    "        test_score_list.append(le_severe_score)\n",
    "    \n",
    "    test_eye_dict[\"pid_list\"] = test_pid_list\n",
    "    test_eye_dict[\"year_list\"] = test_year_list\n",
    "    test_eye_dict[\"eye_list\"] = test_eye_list\n",
    "    test_eye_dict[\"label_list\"] = test_label_list\n",
    "    test_eye_dict[\"score_list\"] = test_score_list\n",
    "    \n",
    "    return {\"train_set\" : train_eye_dict, \"validation_set\" : validation_eye_dict, \"test_set\" : test_eye_dict}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitted_patient_verification_data_dict = build_splitted_patient_verification_data_dict(splitted_patient_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_longitudinal_sequential_prediction_verification_data_dict(splitted_patient_dict, timedelta, remove_recurrent=True, generate_per_len_test_set=True):\n",
    "    \n",
    "    train_set = splitted_patient_dict[\"train_set\"]\n",
    "    validation_set = splitted_patient_dict[\"validation_set\"]\n",
    "    test_set = splitted_patient_dict[\"test_set\"]\n",
    "    \n",
    "    train_eye_dict = dict()\n",
    "    validation_eye_dict = dict()\n",
    "    test_eye_dict = dict()\n",
    "    \n",
    "    train_pid_list = []\n",
    "    train_year_list = []\n",
    "    train_eye_list = []\n",
    "    train_label_list = []\n",
    "    \n",
    "    validation_pid_list = []\n",
    "    validation_year_list = []\n",
    "    validation_eye_list = []\n",
    "    validation_label_list = []\n",
    "\n",
    "    test_pid_list = []\n",
    "    test_year_list = []\n",
    "    test_eye_list = []\n",
    "    test_label_list = []\n",
    "    \n",
    "    train_eye_exclusion_count = 0\n",
    "    validation_eye_exclusion_count = 0\n",
    "    test_eye_exclusion_count = 0\n",
    "    \n",
    "    # train set\n",
    "    for pid, value in train_set.items():\n",
    "        \n",
    "        re_year = np.array(value[\"re\"][\"re_year\"])\n",
    "        re_img_list = value[\"re\"][\"re_img\"]\n",
    "        re_severe_score = value[\"re\"][\"re_severe_score\"]\n",
    "        re_late_amd = np.array(value[\"re\"][\"re_late_amd\"])\n",
    "        \n",
    "        if len(re_img_list) != len(re_late_amd):\n",
    "            raise ValueError(\"the length of img_list and label_list must be the same\")\n",
    "        \n",
    "        le_year = np.array(value[\"le\"][\"le_year\"])\n",
    "        le_img_list = value[\"le\"][\"le_img\"]\n",
    "        le_severe_score = value[\"le\"][\"le_severe_score\"]\n",
    "        le_late_amd = np.array(value[\"le\"][\"le_late_amd\"])\n",
    "        \n",
    "        if len(le_img_list) != len(le_late_amd):\n",
    "            raise ValueError(\"the length of img_list and label_list must be the same\")\n",
    "            \n",
    "        if remove_recurrent:\n",
    "            \n",
    "            if np.sum(re_late_amd) > 0: # test whether the eye had late-amd status\n",
    "                re_first_late_amd_idx = np.where(re_late_amd == 1)[0][0]\n",
    "                re_year = re_year[:re_first_late_amd_idx+1]\n",
    "                re_img_list = re_img_list[:re_first_late_amd_idx+1]\n",
    "                re_severe_score = re_severe_score[:re_first_late_amd_idx+1]\n",
    "                re_late_amd = re_late_amd[:re_first_late_amd_idx+1]\n",
    "                \n",
    "            if np.sum(le_late_amd) > 0: # test whether the eye had late-amd status\n",
    "                le_first_late_amd_idx = np.where(le_late_amd == 1)[0][0]\n",
    "                le_year = le_year[:le_first_late_amd_idx+1]\n",
    "                le_img_list = le_img_list[:le_first_late_amd_idx+1]\n",
    "                le_severe_score = le_severe_score[:le_first_late_amd_idx+1]\n",
    "                le_late_amd = le_late_amd[:le_first_late_amd_idx+1]\n",
    "            \n",
    "        re_total_year_len = re_year[-1] - re_year[0]\n",
    "        le_total_year_len = le_year[-1] - le_year[0]\n",
    "        re_label_list = []\n",
    "        le_label_list = []\n",
    "        \n",
    "        if re_total_year_len >= timedelta:\n",
    "            for idx, (year, img) in enumerate(zip(re_year, re_img_list)):\n",
    "                \n",
    "                if idx == (len(re_year)-1):\n",
    "                    continue\n",
    "                else:\n",
    "                    label_year_end = year + timedelta\n",
    "                    label_year_ind1 = np.where(re_year > year, True, False)\n",
    "                    label_year_ind2 = np.where(re_year <= label_year_end, True, False)\n",
    "                    label_ind = label_year_ind1 * label_year_ind2\n",
    "                \n",
    "                    if np.sum(label_ind) > 0:\n",
    "                        re_label_list.append(int(np.max(re_late_amd[label_ind])))\n",
    "                    else:\n",
    "                        re_label_list.append(re_late_amd[idx+1])\n",
    "            \n",
    "        else:\n",
    "            train_eye_exclusion_count += 1\n",
    "            \n",
    "        if le_total_year_len >= timedelta:\n",
    "            for idx, (year, img) in enumerate(zip(le_year, le_img_list)):\n",
    "                \n",
    "                if idx == (len(le_year)-1):\n",
    "                    continue\n",
    "                else:\n",
    "                    label_year_end = year + timedelta\n",
    "                    label_year_ind1 = np.where(le_year > year, True, False)\n",
    "                    label_year_ind2 = np.where(le_year <= label_year_end, True, False)\n",
    "                    label_ind = label_year_ind1 * label_year_ind2\n",
    "                \n",
    "                    if np.sum(label_ind) > 0:\n",
    "                        le_label_list.append(int(np.max(le_late_amd[label_ind])))\n",
    "                    else:\n",
    "                        le_label_list.append(le_late_amd[idx+1])\n",
    "            \n",
    "        else:\n",
    "            train_eye_exclusion_count += 1\n",
    "            \n",
    "        if len(re_label_list) > 0:\n",
    "            assert len(re_img_list[:-1]) == len(re_label_list), \"length of the label list and img list must be the same\"\n",
    "            train_pid_list.append(pid+\"_re\")\n",
    "            train_year_list.append(list(re_year[:-1]))\n",
    "            train_eye_list.append(re_img_list[:-1])\n",
    "            train_label_list.append(re_label_list)\n",
    "        \n",
    "        if len(le_label_list) > 0:\n",
    "            assert len(le_img_list[:-1]) == len(le_label_list), \"length of the label list and img list must be the same\"\n",
    "            train_pid_list.append(pid+\"_le\")\n",
    "            train_year_list.append(list(le_year[:-1]))\n",
    "            train_eye_list.append(le_img_list[:-1])\n",
    "            train_label_list.append(le_label_list)\n",
    "    \n",
    "    train_eye_dict[\"pid_list\"] = train_pid_list\n",
    "    train_eye_dict[\"year_list\"] = train_year_list\n",
    "    train_eye_dict[\"eye_list\"] = train_eye_list\n",
    "    train_eye_dict[\"label_list\"] = train_label_list\n",
    "    \n",
    "    # validation set\n",
    "    for pid, value in validation_set.items():\n",
    "        \n",
    "        re_year = np.array(value[\"re\"][\"re_year\"])\n",
    "        re_img_list = value[\"re\"][\"re_img\"]\n",
    "        re_severe_score = value[\"re\"][\"re_severe_score\"]\n",
    "        re_late_amd = np.array(value[\"re\"][\"re_late_amd\"])\n",
    "        \n",
    "        if len(re_img_list) != len(re_late_amd):\n",
    "            raise ValueError(\"the length of img_list and label_list must be the same\")\n",
    "        \n",
    "        le_year = np.array(value[\"le\"][\"le_year\"])\n",
    "        le_img_list = value[\"le\"][\"le_img\"]\n",
    "        le_severe_score = value[\"le\"][\"le_severe_score\"]\n",
    "        le_late_amd = np.array(value[\"le\"][\"le_late_amd\"])\n",
    "        \n",
    "        if len(le_img_list) != len(le_late_amd):\n",
    "            raise ValueError(\"the length of img_list and label_list must be the same\")\n",
    "            \n",
    "        if remove_recurrent:\n",
    "            \n",
    "            if np.sum(re_late_amd) > 0: # test whether the eye had late-amd status\n",
    "                re_first_late_amd_idx = np.where(re_late_amd == 1)[0][0]\n",
    "                re_year = re_year[:re_first_late_amd_idx+1]\n",
    "                re_img_list = re_img_list[:re_first_late_amd_idx+1]\n",
    "                re_severe_score = re_severe_score[:re_first_late_amd_idx+1]\n",
    "                re_late_amd = re_late_amd[:re_first_late_amd_idx+1]\n",
    "                \n",
    "            if np.sum(le_late_amd) > 0: # test whether the eye had late-amd status\n",
    "                le_first_late_amd_idx = np.where(le_late_amd == 1)[0][0]\n",
    "                le_year = le_year[:le_first_late_amd_idx+1]\n",
    "                le_img_list = le_img_list[:le_first_late_amd_idx+1]\n",
    "                le_severe_score = le_severe_score[:le_first_late_amd_idx+1]\n",
    "                le_late_amd = le_late_amd[:le_first_late_amd_idx+1]\n",
    "            \n",
    "        re_total_year_len = re_year[-1] - re_year[0]\n",
    "        le_total_year_len = le_year[-1] - le_year[0]\n",
    "        re_label_list = []\n",
    "        le_label_list = []\n",
    "        \n",
    "        if re_total_year_len >= timedelta:\n",
    "            for idx, (year, img) in enumerate(zip(re_year, re_img_list)):\n",
    "                \n",
    "                if idx == (len(re_year)-1):\n",
    "                    continue\n",
    "                else:\n",
    "                    label_year_end = year + timedelta\n",
    "                    label_year_ind1 = np.where(re_year > year, True, False)\n",
    "                    label_year_ind2 = np.where(re_year <= label_year_end, True, False)\n",
    "                    label_ind = label_year_ind1 * label_year_ind2\n",
    "                \n",
    "                    if np.sum(label_ind) > 0:\n",
    "                        re_label_list.append(int(np.max(re_late_amd[label_ind])))\n",
    "                    else:\n",
    "                        re_label_list.append(re_late_amd[idx+1])\n",
    "            \n",
    "        else:\n",
    "            validation_eye_exclusion_count += 1\n",
    "            \n",
    "        if le_total_year_len >= timedelta:\n",
    "            for idx, (year, img) in enumerate(zip(le_year, le_img_list)):\n",
    "                \n",
    "                if idx == (len(le_year)-1):\n",
    "                    continue\n",
    "                else:\n",
    "                    label_year_end = year + timedelta\n",
    "                    label_year_ind1 = np.where(le_year > year, True, False)\n",
    "                    label_year_ind2 = np.where(le_year <= label_year_end, True, False)\n",
    "                    label_ind = label_year_ind1 * label_year_ind2\n",
    "                \n",
    "                    if np.sum(label_ind) > 0:\n",
    "                        le_label_list.append(int(np.max(le_late_amd[label_ind])))\n",
    "                    else:\n",
    "                        le_label_list.append(le_late_amd[idx+1])\n",
    "            \n",
    "        else:\n",
    "            train_eye_exclusion_count += 1\n",
    "            \n",
    "        if len(re_label_list) > 0:\n",
    "            assert len(re_img_list[:-1]) == len(re_label_list), \"length of the label list and img list must be the same\"\n",
    "            validation_pid_list.append(pid+\"_re\")\n",
    "            validation_year_list.append(list(re_year[:-1]))\n",
    "            validation_eye_list.append(re_img_list[:-1])\n",
    "            validation_label_list.append(re_label_list)\n",
    "        \n",
    "        if len(le_label_list) > 0:\n",
    "            assert len(le_img_list[:-1]) == len(le_label_list), \"length of the label list and img list must be the same\"\n",
    "            validation_pid_list.append(pid+\"_le\")\n",
    "            validation_year_list.append(list(le_year[:-1]))\n",
    "            validation_eye_list.append(le_img_list[:-1])\n",
    "            validation_label_list.append(le_label_list)\n",
    "            \n",
    "    validation_eye_dict[\"pid_list\"] = validation_pid_list\n",
    "    validation_eye_dict[\"year_list\"] = validation_year_list\n",
    "    validation_eye_dict[\"eye_list\"] = validation_eye_list\n",
    "    validation_eye_dict[\"label_list\"] = validation_label_list\n",
    "    \n",
    "    # test set\n",
    "    for pid, value in test_set.items():\n",
    "        \n",
    "        re_year = np.array(value[\"re\"][\"re_year\"])\n",
    "        re_img_list = value[\"re\"][\"re_img\"]\n",
    "        re_severe_score = value[\"re\"][\"re_severe_score\"]\n",
    "        re_late_amd = np.array(value[\"re\"][\"re_late_amd\"])\n",
    "        \n",
    "        if len(re_img_list) != len(re_late_amd):\n",
    "            raise ValueError(\"the length of img_list and label_list must be the same\")\n",
    "        \n",
    "        le_year = np.array(value[\"le\"][\"le_year\"])\n",
    "        le_img_list = value[\"le\"][\"le_img\"]\n",
    "        le_severe_score = value[\"le\"][\"le_severe_score\"]\n",
    "        le_late_amd = np.array(value[\"le\"][\"le_late_amd\"])\n",
    "        \n",
    "        if len(le_img_list) != len(le_late_amd):\n",
    "            raise ValueError(\"the length of img_list and label_list must be the same\")\n",
    "            \n",
    "        if remove_recurrent:\n",
    "            \n",
    "            if np.sum(re_late_amd) > 0: # test whether the eye had late-amd status\n",
    "                re_first_late_amd_idx = np.where(re_late_amd == 1)[0][0]\n",
    "                re_year = re_year[:re_first_late_amd_idx+1]\n",
    "                re_img_list = re_img_list[:re_first_late_amd_idx+1]\n",
    "                re_severe_score = re_severe_score[:re_first_late_amd_idx+1]\n",
    "                re_late_amd = re_late_amd[:re_first_late_amd_idx+1]\n",
    "                \n",
    "            if np.sum(le_late_amd) > 0: # test whether the eye had late-amd status\n",
    "                le_first_late_amd_idx = np.where(le_late_amd == 1)[0][0]\n",
    "                le_year = le_year[:le_first_late_amd_idx+1]\n",
    "                le_img_list = le_img_list[:le_first_late_amd_idx+1]\n",
    "                le_severe_score = le_severe_score[:le_first_late_amd_idx+1]\n",
    "                le_late_amd = le_late_amd[:le_first_late_amd_idx+1]\n",
    "            \n",
    "        re_total_year_len = re_year[-1] - re_year[0]\n",
    "        le_total_year_len = le_year[-1] - le_year[0]\n",
    "        re_label_list = []\n",
    "        le_label_list = []\n",
    "        \n",
    "        if re_total_year_len >= timedelta:\n",
    "            for idx, (year, img) in enumerate(zip(re_year, re_img_list)):\n",
    "                \n",
    "                if idx == (len(re_year)-1):\n",
    "                    continue\n",
    "                else:\n",
    "                    label_year_end = year + timedelta\n",
    "                    label_year_ind1 = np.where(re_year > year, True, False)\n",
    "                    label_year_ind2 = np.where(re_year <= label_year_end, True, False)\n",
    "                    label_ind = label_year_ind1 * label_year_ind2\n",
    "                \n",
    "                    if np.sum(label_ind) > 0:\n",
    "                        re_label_list.append(int(np.max(re_late_amd[label_ind])))\n",
    "                    else:\n",
    "                        re_label_list.append(re_late_amd[idx+1])\n",
    "            \n",
    "        else:\n",
    "            test_eye_exclusion_count += 1\n",
    "            \n",
    "        if le_total_year_len >= timedelta:\n",
    "            for idx, (year, img) in enumerate(zip(le_year, le_img_list)):\n",
    "                \n",
    "                if idx == (len(le_year)-1):\n",
    "                    continue\n",
    "                else:\n",
    "                    label_year_end = year + timedelta\n",
    "                    label_year_ind1 = np.where(le_year > year, True, False)\n",
    "                    label_year_ind2 = np.where(le_year <= label_year_end, True, False)\n",
    "                    label_ind = label_year_ind1 * label_year_ind2\n",
    "                \n",
    "                    if np.sum(label_ind) > 0:\n",
    "                        le_label_list.append(int(np.max(le_late_amd[label_ind])))\n",
    "                    else:\n",
    "                        le_label_list.append(le_late_amd[idx+1])\n",
    "            \n",
    "        else:\n",
    "            train_eye_exclusion_count += 1\n",
    "            \n",
    "        if len(re_label_list) > 0:\n",
    "            assert len(re_img_list[:-1]) == len(re_label_list), \"length of the label list and img list must be the same\"\n",
    "            test_pid_list.append(pid+\"_re\")\n",
    "            test_year_list.append(list(re_year[:-1]))\n",
    "            test_eye_list.append(re_img_list[:-1])\n",
    "            test_label_list.append(re_label_list)\n",
    "        \n",
    "        if len(le_label_list) > 0:\n",
    "            assert len(le_img_list[:-1]) == len(le_label_list), \"length of the label list and img list must be the same\"\n",
    "            test_pid_list.append(pid+\"_le\")\n",
    "            test_year_list.append(list(le_year[:-1]))\n",
    "            test_eye_list.append(le_img_list[:-1])\n",
    "            test_label_list.append(le_label_list)\n",
    "            \n",
    "    test_eye_dict[\"pid_list\"] = test_pid_list\n",
    "    test_eye_dict[\"year_list\"] = test_year_list\n",
    "    test_eye_dict[\"eye_list\"] = test_eye_list\n",
    "    test_eye_dict[\"label_list\"] = test_label_list\n",
    "    \n",
    "    if generate_per_len_test_set:\n",
    "        \n",
    "        per_len_test_eye_dict = dict()\n",
    "        \n",
    "        max_len = 0\n",
    "        \n",
    "        for eye_img_list in test_eye_list:\n",
    "            if len(eye_img_list) > max_len:\n",
    "                max_len = len(eye_img_list)\n",
    "                \n",
    "        for length in range(max_len):\n",
    "            per_len_test_eye_dict[length+1] = {\"pid_list\" : [], \"year_list\" : [], \"eye_list\" : [], \"label_list\" : []}\n",
    "        \n",
    "        for pid, years, eyes, labels in zip(test_pid_list, test_year_list, test_eye_list, test_label_list):\n",
    "            \n",
    "            for idx, (year, eye, label) in enumerate(zip(years, eyes, labels)):\n",
    "                per_len_test_eye_dict[idx+1][\"pid_list\"].append(pid)\n",
    "                per_len_test_eye_dict[idx+1][\"year_list\"].append(years[:(idx+1)])\n",
    "                per_len_test_eye_dict[idx+1][\"eye_list\"].append(eyes[:(idx+1)])\n",
    "                per_len_test_eye_dict[idx+1][\"label_list\"].append(labels[:(idx+1)])\n",
    "    \n",
    "    return {\"train_set\" : train_eye_dict, \"validation_set\" : validation_eye_dict, \"test_set\" : test_eye_dict, \"per_length_test_set\" : per_len_test_eye_dict}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "longitudinal_sequential_prediction_timedelta2_verification_data_dict = build_longitudinal_sequential_prediction_verification_data_dict(splitted_patient_dict, timedelta=2, remove_recurrent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sequential_prediction_verification_data_dict_to_csv(output_path, verification_data_dict):\n",
    "    \n",
    "    train_pid_list = verification_data_dict[\"train_set\"][\"pid_list\"]\n",
    "    train_year_list = verification_data_dict[\"train_set\"][\"year_list\"]\n",
    "    train_eye_list = verification_data_dict[\"train_set\"][\"eye_list\"]\n",
    "    train_label_list = verification_data_dict[\"train_set\"][\"label_list\"]\n",
    "    \n",
    "    validation_pid_list = verification_data_dict[\"validation_set\"][\"pid_list\"]\n",
    "    validation_year_list = verification_data_dict[\"validation_set\"][\"year_list\"]\n",
    "    validation_eye_list = verification_data_dict[\"validation_set\"][\"eye_list\"]\n",
    "    validation_label_list = verification_data_dict[\"validation_set\"][\"label_list\"]\n",
    "\n",
    "    test_pid_list = verification_data_dict[\"test_set\"][\"pid_list\"]\n",
    "    test_year_list = verification_data_dict[\"test_set\"][\"year_list\"]\n",
    "    test_eye_list = verification_data_dict[\"test_set\"][\"eye_list\"]\n",
    "    test_label_list = verification_data_dict[\"test_set\"][\"label_list\"]\n",
    "    \n",
    "    train_df_dict = dict()\n",
    "    validation_df_dict = dict()\n",
    "    test_df_dict = dict()\n",
    "    \n",
    "    for idx, (pid, years, eyes, labels) in enumerate(zip(train_pid_list, train_year_list, train_eye_list, train_label_list)):\n",
    "        train_df_dict[pid] = [years, eyes, labels]\n",
    "        \n",
    "    for idx, (pid, years, eyes, labels) in enumerate(zip(validation_pid_list, validation_year_list, validation_eye_list, validation_label_list)):\n",
    "        validation_df_dict[pid] = [years, eyes, labels]\n",
    "\n",
    "    for idx, (pid, years, eyes, labels) in enumerate(zip(test_pid_list, test_year_list, test_eye_list, test_label_list)):\n",
    "        test_df_dict[pid] = [years, eyes, labels]\n",
    "        \n",
    "    train_df = pd.DataFrame.from_dict(train_df_dict, orient='index', columns=['year', 'eye', 'label'])\n",
    "    train_df.index.name = \"pid\"\n",
    "    train_df.to_csv(os.path.join(output_path, \"train_set_df.csv\"), index=True)\n",
    "    validation_df = pd.DataFrame.from_dict(validation_df_dict, orient='index', columns=['year', 'eye', 'label'])\n",
    "    validation_df.to_csv(os.path.join(output_path, \"validation_set_df.csv\"), index=True)\n",
    "    validation_df.index.name = \"pid\"\n",
    "    test_df = pd.DataFrame.from_dict(test_df_dict, orient='index', columns=['year', 'eye', 'label'])\n",
    "    test_df.index.name = \"pid\"\n",
    "    test_df.to_csv(os.path.join(output_path, \"test_set_df.csv\"), index=True)\n",
    "    \n",
    "    per_len_test_eye_dict = verification_data_dict[\"per_length_test_set\"]\n",
    "    unique_length = list(per_len_test_eye_dict.keys())\n",
    "        \n",
    "    for length in unique_length:\n",
    "        this_length_test_eye_dict = per_len_test_eye_dict[length]\n",
    "        this_length_test_df_dict = dict()\n",
    "            \n",
    "        this_length_test_pid_list = this_length_test_eye_dict[\"pid_list\"]\n",
    "        this_length_test_year_list = this_length_test_eye_dict[\"year_list\"]\n",
    "        this_length_test_eye_list = this_length_test_eye_dict[\"eye_list\"]\n",
    "        this_length_test_label_list = this_length_test_eye_dict[\"label_list\"]\n",
    "            \n",
    "        for idx, (pid, years, eyes, labels) in enumerate(zip(this_length_test_pid_list, this_length_test_year_list, this_length_test_eye_list, this_length_test_label_list)):\n",
    "            this_length_test_df_dict[pid] = [length, years, eyes, labels]\n",
    "                \n",
    "        this_length_test_df = pd.DataFrame.from_dict(this_length_test_df_dict, orient='index', columns=['length', 'year', 'eye', 'label'])\n",
    "        this_length_test_df.index.name = \"pid\"\n",
    "        \n",
    "        if length == 1:\n",
    "            per_length_test_df = this_length_test_df\n",
    "        else:\n",
    "            per_length_test_df = pd.concat([per_length_test_df, this_length_test_df])\n",
    "        \n",
    "    per_length_test_df.to_csv(os.path.join(output_path, \"per_length_test_set_df.csv\"), index=True)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitted_patient_verification_data_dict_to_csv(output_path, verification_data_dict):\n",
    "    \n",
    "    train_pid_list = verification_data_dict[\"train_set\"][\"pid_list\"]\n",
    "    train_year_list = verification_data_dict[\"train_set\"][\"year_list\"]\n",
    "    train_eye_list = verification_data_dict[\"train_set\"][\"eye_list\"]\n",
    "    train_label_list = verification_data_dict[\"train_set\"][\"label_list\"]\n",
    "    train_score_list = verification_data_dict[\"train_set\"][\"score_list\"]\n",
    "    \n",
    "    validation_pid_list = verification_data_dict[\"validation_set\"][\"pid_list\"]\n",
    "    validation_year_list = verification_data_dict[\"validation_set\"][\"year_list\"]\n",
    "    validation_eye_list = verification_data_dict[\"validation_set\"][\"eye_list\"]\n",
    "    validation_label_list = verification_data_dict[\"validation_set\"][\"label_list\"]\n",
    "    validation_score_list = verification_data_dict[\"validation_set\"][\"score_list\"]\n",
    "\n",
    "    test_pid_list = verification_data_dict[\"test_set\"][\"pid_list\"]\n",
    "    test_year_list = verification_data_dict[\"test_set\"][\"year_list\"]\n",
    "    test_eye_list = verification_data_dict[\"test_set\"][\"eye_list\"]\n",
    "    test_label_list = verification_data_dict[\"test_set\"][\"label_list\"]\n",
    "    test_score_list = verification_data_dict[\"test_set\"][\"score_list\"]\n",
    "    \n",
    "    train_df_dict = dict()\n",
    "    validation_df_dict = dict()\n",
    "    test_df_dict = dict()\n",
    "    \n",
    "    for idx, (pid, years, eyes, labels, scores) in enumerate(zip(train_pid_list, train_year_list, train_eye_list, train_label_list, train_score_list)):\n",
    "        train_df_dict[pid] = [years, eyes, labels, scores]\n",
    "        \n",
    "    for idx, (pid, years, eyes, labels, scores) in enumerate(zip(validation_pid_list, validation_year_list, validation_eye_list, validation_label_list, validation_score_list)):\n",
    "        validation_df_dict[pid] = [years, eyes, labels, scores]\n",
    "\n",
    "    for idx, (pid, years, eyes, labels, scores) in enumerate(zip(test_pid_list, test_year_list, test_eye_list, test_label_list, test_score_list)):\n",
    "        test_df_dict[pid] = [years, eyes, labels, scores]\n",
    "        \n",
    "    train_df = pd.DataFrame.from_dict(train_df_dict, orient='index', columns=['year', 'eye', 'label', 'score'])\n",
    "    train_df.index.name = \"pid\"\n",
    "    train_df.to_csv(os.path.join(output_path, \"train_set_df.csv\"), index=True)\n",
    "    validation_df = pd.DataFrame.from_dict(validation_df_dict, orient='index', columns=['year', 'eye', 'label', 'score'])\n",
    "    validation_df.to_csv(os.path.join(output_path, \"validation_set_df.csv\"), index=True)\n",
    "    validation_df.index.name = \"pid\"\n",
    "    test_df = pd.DataFrame.from_dict(test_df_dict, orient='index', columns=['year', 'eye', 'label', 'score'])\n",
    "    test_df.index.name = \"pid\"\n",
    "    test_df.to_csv(os.path.join(output_path, \"test_set_df.csv\"), index=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "verification_data_dict_to_csv(\"/home/jl5307/current_research/AMD_prediction/img_data/verification_data/sequential_prediction_timedelta2/\", longitudinal_sequential_prediction_timedelta2_verification_data_dict, per_length_test_set=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitted_patient_verification_data_dict_to_csv(\"/home/jl5307/current_research/AMD_prediction/img_data/verification_data/splitted_patient/\", splitted_patient_verification_data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pid</th>\n",
       "      <th>year</th>\n",
       "      <th>eye</th>\n",
       "      <th>label</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>G273_re</td>\n",
       "      <td>[0.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.5, 9.0, ...</td>\n",
       "      <td>['56516 QUA F2 RE LS.jpg', '56516 04 F2 RE LS....</td>\n",
       "      <td>[0 0 0 0 0 0 0 0 0 0 0 0]</td>\n",
       "      <td>[4.0, 5.0, 5.0, 6.0, 4.0, 4.0, 4.0, 8.0, 5.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>G273_le</td>\n",
       "      <td>[0.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.5, 9.0, ...</td>\n",
       "      <td>['56516 QUA F2 LE LS.jpg', '56516 04 F2 LE LS....</td>\n",
       "      <td>[0 0 0 0 0 0 0 0 0 0 0 0]</td>\n",
       "      <td>[4.0, 5.0, 4.0, 5.0, 2.0, 8.0, 4.0, 8.0, 8.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5460_re</td>\n",
       "      <td>[0.0, 2.0, 3.0, 4.0, 5.0, 7.0, 11.0]</td>\n",
       "      <td>['54545 QUA F2 RE LS.jpg', '54545 04 F2 RE LS....</td>\n",
       "      <td>[0 0 0 0 0 0 0]</td>\n",
       "      <td>[6.0, 6.0, 6.0, 6.0, 7.0, 6.0, 6.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5460_le</td>\n",
       "      <td>[0.0, 2.0, 3.0, 4.0, 5.0, 7.0, 11.0]</td>\n",
       "      <td>['54545 QUA F2 LE LS.jpg', '54545 04 F2 LE LS....</td>\n",
       "      <td>[0 0 0 0 0 0 0]</td>\n",
       "      <td>[6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>G485_re</td>\n",
       "      <td>[0.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, ...</td>\n",
       "      <td>['58404 QUA F2 RE LS.jpg', '58404 04 F2 RE LS....</td>\n",
       "      <td>[0 0 0 0 0 0 0 0 0 0 0]</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6035</th>\n",
       "      <td>4520_le</td>\n",
       "      <td>[0.0, 2.0, 3.0, 4.0, 5.0, 6.0]</td>\n",
       "      <td>['58753 QUA F2 LE LS.jpg', '58753 04 F2 LE LS....</td>\n",
       "      <td>[0 0 0 0 0 1]</td>\n",
       "      <td>[2.0, 5.0, 5.0, 6.0, 7.0, 11.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6036</th>\n",
       "      <td>3912_re</td>\n",
       "      <td>[0.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.5, 9.0, ...</td>\n",
       "      <td>['56163 QUA F2 RE LS.jpg', '56163 04 F2 RE LS....</td>\n",
       "      <td>[0 0 0 0 0 0 0 0 0 0 0 0]</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6037</th>\n",
       "      <td>3912_le</td>\n",
       "      <td>[0.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.5, 9.0, ...</td>\n",
       "      <td>['56163 QUA F2 LE LS.jpg', '56163 04 F2 LE LS....</td>\n",
       "      <td>[0 0 0 0 0 0 0 0 0 0 0 0]</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6038</th>\n",
       "      <td>3537_re</td>\n",
       "      <td>[0.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, ...</td>\n",
       "      <td>['61695 QUA F2 RE LS.jpg', '61695 04 F2 RE LS....</td>\n",
       "      <td>[0 0 0 0 0 0 0 0 0 0]</td>\n",
       "      <td>[1.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0, 1.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6039</th>\n",
       "      <td>3537_le</td>\n",
       "      <td>[0.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, ...</td>\n",
       "      <td>['61695 QUA F2 LE LS.jpg', '61695 04 F2 LE LS....</td>\n",
       "      <td>[0 0 0 0 0 0 0 0 0 0]</td>\n",
       "      <td>[2.0, 2.0, 2.0, 4.0, 4.0, 3.0, 3.0, 3.0, 5.0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6040 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          pid                                               year  \\\n",
       "0     G273_re  [0.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.5, 9.0, ...   \n",
       "1     G273_le  [0.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.5, 9.0, ...   \n",
       "2     5460_re               [0.0, 2.0, 3.0, 4.0, 5.0, 7.0, 11.0]   \n",
       "3     5460_le               [0.0, 2.0, 3.0, 4.0, 5.0, 7.0, 11.0]   \n",
       "4     G485_re  [0.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, ...   \n",
       "...       ...                                                ...   \n",
       "6035  4520_le                     [0.0, 2.0, 3.0, 4.0, 5.0, 6.0]   \n",
       "6036  3912_re  [0.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.5, 9.0, ...   \n",
       "6037  3912_le  [0.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.5, 9.0, ...   \n",
       "6038  3537_re  [0.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, ...   \n",
       "6039  3537_le  [0.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, ...   \n",
       "\n",
       "                                                    eye  \\\n",
       "0     ['56516 QUA F2 RE LS.jpg', '56516 04 F2 RE LS....   \n",
       "1     ['56516 QUA F2 LE LS.jpg', '56516 04 F2 LE LS....   \n",
       "2     ['54545 QUA F2 RE LS.jpg', '54545 04 F2 RE LS....   \n",
       "3     ['54545 QUA F2 LE LS.jpg', '54545 04 F2 LE LS....   \n",
       "4     ['58404 QUA F2 RE LS.jpg', '58404 04 F2 RE LS....   \n",
       "...                                                 ...   \n",
       "6035  ['58753 QUA F2 LE LS.jpg', '58753 04 F2 LE LS....   \n",
       "6036  ['56163 QUA F2 RE LS.jpg', '56163 04 F2 RE LS....   \n",
       "6037  ['56163 QUA F2 LE LS.jpg', '56163 04 F2 LE LS....   \n",
       "6038  ['61695 QUA F2 RE LS.jpg', '61695 04 F2 RE LS....   \n",
       "6039  ['61695 QUA F2 LE LS.jpg', '61695 04 F2 LE LS....   \n",
       "\n",
       "                          label  \\\n",
       "0     [0 0 0 0 0 0 0 0 0 0 0 0]   \n",
       "1     [0 0 0 0 0 0 0 0 0 0 0 0]   \n",
       "2               [0 0 0 0 0 0 0]   \n",
       "3               [0 0 0 0 0 0 0]   \n",
       "4       [0 0 0 0 0 0 0 0 0 0 0]   \n",
       "...                         ...   \n",
       "6035              [0 0 0 0 0 1]   \n",
       "6036  [0 0 0 0 0 0 0 0 0 0 0 0]   \n",
       "6037  [0 0 0 0 0 0 0 0 0 0 0 0]   \n",
       "6038      [0 0 0 0 0 0 0 0 0 0]   \n",
       "6039      [0 0 0 0 0 0 0 0 0 0]   \n",
       "\n",
       "                                                  score  \n",
       "0     [4.0, 5.0, 5.0, 6.0, 4.0, 4.0, 4.0, 8.0, 5.0, ...  \n",
       "1     [4.0, 5.0, 4.0, 5.0, 2.0, 8.0, 4.0, 8.0, 8.0, ...  \n",
       "2                   [6.0, 6.0, 6.0, 6.0, 7.0, 6.0, 6.0]  \n",
       "3                   [6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0]  \n",
       "4     [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, ...  \n",
       "...                                                 ...  \n",
       "6035                    [2.0, 5.0, 5.0, 6.0, 7.0, 11.0]  \n",
       "6036  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...  \n",
       "6037  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...  \n",
       "6038  [1.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0, 1.0, ...  \n",
       "6039  [2.0, 2.0, 2.0, 4.0, 4.0, 3.0, 3.0, 3.0, 5.0, ...  \n",
       "\n",
       "[6040 rows x 5 columns]"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(\"/home/jl5307/current_research/AMD_prediction/img_data/verification_data/splitted_patient/train_set_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "d2 = pd.read_csv(\"/home/jl5307/current_research/AMD_prediction/img_data/verification_data/per_length_test_set_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pid</th>\n",
       "      <th>length</th>\n",
       "      <th>year</th>\n",
       "      <th>eye</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>G183_re</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.0]</td>\n",
       "      <td>['54654 QUA F2 RE LS.jpg']</td>\n",
       "      <td>[0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>G183_le</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.0]</td>\n",
       "      <td>['54654 QUA F2 LE LS.jpg']</td>\n",
       "      <td>[0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4693_re</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.0]</td>\n",
       "      <td>['58574 QUA F2 RE LS.jpg']</td>\n",
       "      <td>[0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1866_re</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.0]</td>\n",
       "      <td>['59659 QUA F2 RE LS.jpg']</td>\n",
       "      <td>[0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1866_le</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.0]</td>\n",
       "      <td>['59659 QUA F2 LE LS.jpg']</td>\n",
       "      <td>[1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7424</th>\n",
       "      <td>4341_le</td>\n",
       "      <td>12</td>\n",
       "      <td>[0.0, 2.0, 3.0, 4.0, 4.5, 5.0, 6.0, 7.0, 7.5, ...</td>\n",
       "      <td>['52539 QUA F2 LE LS.jpg', '52539 04 F2 LE LS....</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7425</th>\n",
       "      <td>2255_re</td>\n",
       "      <td>12</td>\n",
       "      <td>[0.0, 0.5, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, ...</td>\n",
       "      <td>['57115 QUA F2 RE LS.jpg', '57115 01 F2 RE LS....</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7426</th>\n",
       "      <td>2255_le</td>\n",
       "      <td>12</td>\n",
       "      <td>[0.0, 0.5, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, ...</td>\n",
       "      <td>['57115 QUA F2 LE LS.jpg', '57115 01 F2 LE LS....</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7427</th>\n",
       "      <td>3250_re</td>\n",
       "      <td>12</td>\n",
       "      <td>[0.0, 2.0, 3.0, 3.5, 4.0, 5.0, 6.0, 7.0, 7.5, ...</td>\n",
       "      <td>['57132 QUA F2 RE LS.jpg', '57132 04 F2 RE LS....</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7428</th>\n",
       "      <td>3250_le</td>\n",
       "      <td>12</td>\n",
       "      <td>[0.0, 2.0, 3.0, 3.5, 4.0, 5.0, 6.0, 7.0, 7.5, ...</td>\n",
       "      <td>['57132 QUA F2 LE LS.jpg', '57132 04 F2 LE LS....</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7429 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          pid  length                                               year  \\\n",
       "0     G183_re       1                                              [0.0]   \n",
       "1     G183_le       1                                              [0.0]   \n",
       "2     4693_re       1                                              [0.0]   \n",
       "3     1866_re       1                                              [0.0]   \n",
       "4     1866_le       1                                              [0.0]   \n",
       "...       ...     ...                                                ...   \n",
       "7424  4341_le      12  [0.0, 2.0, 3.0, 4.0, 4.5, 5.0, 6.0, 7.0, 7.5, ...   \n",
       "7425  2255_re      12  [0.0, 0.5, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, ...   \n",
       "7426  2255_le      12  [0.0, 0.5, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, ...   \n",
       "7427  3250_re      12  [0.0, 2.0, 3.0, 3.5, 4.0, 5.0, 6.0, 7.0, 7.5, ...   \n",
       "7428  3250_le      12  [0.0, 2.0, 3.0, 3.5, 4.0, 5.0, 6.0, 7.0, 7.5, ...   \n",
       "\n",
       "                                                    eye  \\\n",
       "0                            ['54654 QUA F2 RE LS.jpg']   \n",
       "1                            ['54654 QUA F2 LE LS.jpg']   \n",
       "2                            ['58574 QUA F2 RE LS.jpg']   \n",
       "3                            ['59659 QUA F2 RE LS.jpg']   \n",
       "4                            ['59659 QUA F2 LE LS.jpg']   \n",
       "...                                                 ...   \n",
       "7424  ['52539 QUA F2 LE LS.jpg', '52539 04 F2 LE LS....   \n",
       "7425  ['57115 QUA F2 RE LS.jpg', '57115 01 F2 RE LS....   \n",
       "7426  ['57115 QUA F2 LE LS.jpg', '57115 01 F2 LE LS....   \n",
       "7427  ['57132 QUA F2 RE LS.jpg', '57132 04 F2 RE LS....   \n",
       "7428  ['57132 QUA F2 LE LS.jpg', '57132 04 F2 LE LS....   \n",
       "\n",
       "                                     label  \n",
       "0                                      [0]  \n",
       "1                                      [0]  \n",
       "2                                      [0]  \n",
       "3                                      [0]  \n",
       "4                                      [1]  \n",
       "...                                    ...  \n",
       "7424  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "7425  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "7426  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "7427  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "7428  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "\n",
       "[7429 rows x 5 columns]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3-workspace",
   "language": "python",
   "name": "python3-workspace"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
