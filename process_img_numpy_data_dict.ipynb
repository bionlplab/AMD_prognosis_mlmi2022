{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import os\n",
    "import cv2\n",
    "import imgaug.augmenters as iaa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_path):\n",
    "    data = pickle.load(open(data_path, 'rb'))\n",
    "\n",
    "    return data\n",
    "\n",
    "def save_data(output_path, mydata):\n",
    "    with open(output_path, 'wb') as f:\n",
    "        \n",
    "        pickle.dump(mydata, f)\n",
    "\n",
    "def count_max_len(mylist):\n",
    "    \n",
    "    max_len = 0\n",
    "    \n",
    "    for l in mylist:\n",
    "        if len(l) > max_len:\n",
    "            max_len = len(l)\n",
    "            \n",
    "    return max_len\n",
    "\n",
    "def set_augmenter():\n",
    "    \n",
    "    augmenter = iaa.Sequential([\n",
    "        iaa.Fliplr(0.5), # horizontal flips with 0.5 probability \n",
    "        iaa.Crop(percent=(0, 0.1)), # random crops\n",
    "        # Apply affine transformations to each image.\n",
    "        # Scale/zoom them, translate/move them, rotate them and shear them.\n",
    "        iaa.Affine(scale={\"x\": (0.95, 1.05), \"y\": (0.95, 1.05)}, translate_percent={\"x\": (-0.05, 0.05), \"y\": (-0.05, 0.05)}, \n",
    "        rotate=(-5, 5), shear=(-2, 2)\n",
    "        )])\n",
    "\n",
    "    return augmenter\n",
    "\n",
    "def parse_image(filename, resizing, scale, augmenter=None):\n",
    "    \n",
    "    image = tf.io.read_file(filename)\n",
    "    image = tf.io.decode_jpeg(image)\n",
    "    image = image.numpy()\n",
    "\n",
    "    if augmenter != None:\n",
    "        image = augmenter(image=image)\n",
    "\n",
    "    image = cv2.addWeighted(image, 4, cv2.GaussianBlur(image, (0,0), 10), -4, 128)\n",
    "    image = tf.image.resize(image, (resizing, resizing)) # 256 * 256\n",
    "    image = tf.image.central_crop(image, scale)\n",
    "    image = tf.cast(image, tf.uint8)\n",
    "    \n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "longitudinal_sequential_prediction_timedelta2_data_dict = load_data(\"/home/jl5307/current_research/AMD_prediction/img_data/data_dictionary/longitudinal_sequential_prediction_timedelta2_data_dict.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "longitudinal_sequential_prediction_timedelta5_data_dict = load_data(\"/home/jl5307/current_research/AMD_prediction/img_data/data_dictionary/longitudinal_sequential_prediction_timedelta5_data_dict.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_numpy_data_set(data_root_path, output_path, longitudinal_sequential_prediction_data_dict, resizing, scale, channel, augment=True):\n",
    "    \n",
    "    train_eye_list = longitudinal_sequential_prediction_data_dict[\"train_set\"][\"eye_list\"]\n",
    "    train_label_list = longitudinal_sequential_prediction_data_dict[\"train_set\"][\"label_list\"]\n",
    "    validation_eye_list = longitudinal_sequential_prediction_data_dict[\"validation_set\"][\"eye_list\"]\n",
    "    validation_label_list = longitudinal_sequential_prediction_data_dict[\"validation_set\"][\"label_list\"]\n",
    "    test_eye_list = longitudinal_sequential_prediction_data_dict[\"test_set\"][\"eye_list\"]\n",
    "    test_label_list = longitudinal_sequential_prediction_data_dict[\"test_set\"][\"label_list\"]\n",
    "    per_legnth_test_dict = longitudinal_sequential_prediction_data_dict[\"per_length_test_set\"]\n",
    "    \n",
    "    max_len_train_set = count_max_len(train_label_list)\n",
    "    max_len_validation_set = count_max_len(validation_label_list)\n",
    "    max_len_test_set = count_max_len(test_label_list)\n",
    "    \n",
    "    train_eye = np.zeros(shape=(len(train_eye_list), max_len_train_set, int(resizing*scale), int(resizing*scale), channel))\n",
    "    train_label = np.zeros(shape=(len(train_label_list), max_len_train_set))\n",
    "    validation_eye = np.zeros(shape=(len(validation_eye_list), max_len_validation_set, int(resizing*scale), int(resizing*scale), channel))\n",
    "    validation_label = np.zeros(shape=(len(validation_label_list), max_len_validation_set))\n",
    "    test_eye = np.zeros(shape=(len(test_eye_list), max_len_test_set, int(resizing*scale), int(resizing*scale), channel))\n",
    "    test_label = np.zeros(shape=(len(test_label_list), max_len_test_set))\n",
    "    \n",
    "    if augment:\n",
    "        augmeter = set_augmenter()\n",
    "    else:\n",
    "        augmeter = None\n",
    "        \n",
    "    print(\"processing training set...\")\n",
    "    progbar = tf.keras.utils.Progbar(len(train_eye_list))\n",
    "    \n",
    "    for list_idx, (eyes, labels) in enumerate(zip(train_eye_list, train_label_list)):\n",
    "\n",
    "        for eye_idx, eye in enumerate(eyes):\n",
    "            eye_filename = data_root_path + eye.split(\" \")[0] + \"/\" + eye\n",
    "            eye_img = parse_image(eye_filename, resizing=resizing, scale=scale, augmenter=augmeter)\n",
    "            train_eye[list_idx, eye_idx, :, :, :] = eye_img\n",
    "        \n",
    "        train_label[list_idx, :len(labels)] = labels\n",
    "        \n",
    "        progbar.add(1)\n",
    "    \n",
    "    print(\"saving training data...\")\n",
    "    np.save(os.path.join(output_path, \"train_eye.npy\"), train_eye)\n",
    "    np.save(os.path.join(output_path, \"train_label.npy\"), train_label)\n",
    "    \n",
    "    # for saving memory\n",
    "    del(train_eye)\n",
    "    del(train_label)\n",
    "    \n",
    "    print(\"processing validation set...\")\n",
    "    progbar = tf.keras.utils.Progbar(len(validation_eye_list))\n",
    "    \n",
    "    for list_idx, (eyes, labels) in enumerate(zip(validation_eye_list, validation_label_list)):\n",
    "\n",
    "        for eye_idx, eye in enumerate(eyes):\n",
    "            eye_filename = data_root_path + eye.split(\" \")[0] + \"/\" + eye\n",
    "            eye_img = parse_image(eye_filename, resizing=resizing, scale=scale, augmenter=None)\n",
    "            validation_eye[list_idx, eye_idx, :, :, :] = eye_img\n",
    "        \n",
    "        validation_label[list_idx, :len(labels)] = labels\n",
    "        \n",
    "        progbar.add(1)\n",
    "        \n",
    "    print(\"saving validation data...\")\n",
    "    np.save(os.path.join(output_path, \"validation_eye.npy\"), validation_eye)\n",
    "    np.save(os.path.join(output_path, \"validation_label.npy\"), validation_label)\n",
    "    \n",
    "    # for saving memory\n",
    "    del(validation_eye)\n",
    "    del(validation_label)\n",
    "    \n",
    "    print(\"processing test set...\")\n",
    "    progbar = tf.keras.utils.Progbar(len(test_eye_list))\n",
    "    \n",
    "    for list_idx, (eyes, labels) in enumerate(zip(test_eye_list, test_label_list)):\n",
    "\n",
    "        for eye_idx, eye in enumerate(eyes):\n",
    "            eye_filename = data_root_path + eye.split(\" \")[0] + \"/\" + eye\n",
    "            eye_img = parse_image(eye_filename, resizing=resizing, scale=scale, augmenter=None)\n",
    "            test_eye[list_idx, eye_idx, :, :, :] = eye_img\n",
    "        \n",
    "        test_label[list_idx, :len(labels)] = labels\n",
    "        \n",
    "        progbar.add(1)\n",
    "        \n",
    "    print(\"saving test data...\")\n",
    "    np.save(os.path.join(output_path, \"test_eye.npy\"), test_eye)\n",
    "    np.save(os.path.join(output_path, \"test_label.npy\"), test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_train_tf_data_set(data_root_path, output_path, longitudinal_sequential_prediction_data_dict, resizing, scale, channel, divide, augment=True):\n",
    "    \n",
    "    train_eye_list = longitudinal_sequential_prediction_data_dict[\"train_set\"][\"eye_list\"]\n",
    "    train_label_list = longitudinal_sequential_prediction_data_dict[\"train_set\"][\"label_list\"]\n",
    "\n",
    "    max_len_train_set = count_max_len(train_label_list)\n",
    "    \n",
    "    division_size = int(np.ceil(len(train_eye_list) / divide))\n",
    "    \n",
    "    for i in range(divide):\n",
    "        \n",
    "        this_split_train_eye_list = train_eye_list[i*division_size:(i+1)*division_size]\n",
    "        this_split_tain_label_list = train_label_list[i*division_size:(i+1)*division_size]\n",
    "        this_split_train_eye = np.zeros(shape=(len(this_split_train_eye_list), max_len_train_set, int(resizing*scale), int(resizing*scale), channel))\n",
    "        this_split_train_label = np.zeros(shape=(len(this_split_tain_label_list), max_len_train_set))\n",
    "\n",
    "        if augment:\n",
    "            augmeter = set_augmenter()\n",
    "        else:\n",
    "            augmeter = None\n",
    "        \n",
    "        print(\"processing training data of {}th split ...\".format(i+1))\n",
    "        progbar = tf.keras.utils.Progbar(len(this_split_train_eye_list))\n",
    "    \n",
    "        for list_idx, (eyes, labels) in enumerate(zip(this_split_train_eye_list, this_split_tain_label_list)):\n",
    "\n",
    "            for eye_idx, eye in enumerate(eyes):\n",
    "                eye_filename = data_root_path + eye.split(\" \")[0] + \"/\" + eye\n",
    "                eye_img = parse_image(eye_filename, resizing=resizing, scale=scale, augmenter=augmeter)\n",
    "                this_split_train_eye[list_idx, eye_idx, :, :, :] = eye_img\n",
    "        \n",
    "            this_split_train_label[list_idx, :len(labels)] = labels\n",
    "            progbar.add(1)\n",
    "    \n",
    "        print(\"saving training data of {}th split...\".format(i+1))\n",
    "        this_split_train_eye_path = os.path.join(output_path, \"train_eye_split{}.npy\".format(i))\n",
    "        this_split_train_label_path = os.path.join(output_path, \"train_label_split{}.npy\".format(i))\n",
    "        np.save(this_split_train_eye_path, this_split_train_eye)\n",
    "        np.save(this_split_train_label_path, this_split_train_label)\n",
    "    \n",
    "        this_split_train_dataset_tf = tf.data.Dataset.from_tensor_slices((this_split_train_eye, this_split_train_label))\n",
    "        this_split_train_dataset_tf_path = os.path.join(output_path, \"train_dataset_tf_split{}\".format(i))\n",
    "        tf.data.experimental.save(this_split_train_dataset_tf, this_split_train_dataset_tf_path)\n",
    "    \n",
    "    train_dataset_tf_element_spec = this_split_train_dataset_tf.element_spec\n",
    "    train_dataset_tf_element_spec_path = os.path.join(output_path, \"train_dataset_tf_element_spec.pkl\")     \n",
    "    save_data(train_dataset_tf_element_spec_path, train_dataset_tf_element_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_validation_tf_data_set(data_root_path, output_path, longitudinal_sequential_prediction_data_dict, resizing, scale, channel):\n",
    "    \n",
    "    validation_eye_list = longitudinal_sequential_prediction_data_dict[\"validation_set\"][\"eye_list\"]\n",
    "    validation_label_list = longitudinal_sequential_prediction_data_dict[\"validation_set\"][\"label_list\"]\n",
    "    \n",
    "    max_len_validation_set = count_max_len(validation_label_list)\n",
    "\n",
    "    validation_eye = np.zeros(shape=(len(validation_eye_list), max_len_validation_set, int(resizing*scale), int(resizing*scale), channel))\n",
    "    validation_label = np.zeros(shape=(len(validation_label_list), max_len_validation_set))\n",
    "    \n",
    "    print(\"processing validation set...\")\n",
    "    progbar = tf.keras.utils.Progbar(len(validation_eye_list))\n",
    "    \n",
    "    for list_idx, (eyes, labels) in enumerate(zip(validation_eye_list, validation_label_list)):\n",
    "\n",
    "        for eye_idx, eye in enumerate(eyes):\n",
    "            eye_filename = data_root_path + eye.split(\" \")[0] + \"/\" + eye\n",
    "            eye_img = parse_image(eye_filename, resizing=resizing, scale=scale, augmenter=None)\n",
    "            validation_eye[list_idx, eye_idx, :, :, :] = eye_img\n",
    "        \n",
    "        validation_label[list_idx, :len(labels)] = labels\n",
    "        \n",
    "        progbar.add(1)\n",
    "        \n",
    "    print(\"saving validation data...\")\n",
    "    np.save(os.path.join(output_path, \"validation_eye.npy\"), validation_eye)\n",
    "    np.save(os.path.join(output_path, \"validation_label.npy\"), validation_label)\n",
    "    \n",
    "    validation_dataset_tf = tf.data.Dataset.from_tensor_slices((validation_eye, validation_label))\n",
    "    validation_dataset_tf_element_spec = validation_dataset_tf.element_spec\n",
    "    validation_dataset_tf_path = os.path.join(output_path, \"validation_dataset_tf\")\n",
    "    validation_dataset_tf_element_spec_path = os.path.join(output_path, \"validation_dataset_tf_element_spec.pkl\")\n",
    "    tf.data.experimental.save(validation_dataset_tf, validation_dataset_tf_path)\n",
    "    save_data(validation_dataset_tf_element_spec_path, validation_dataset_tf_element_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_test_tf_data_set(data_root_path, output_path, longitudinal_sequential_prediction_data_dict, resizing, scale, channel):\n",
    "\n",
    "    test_eye_list = longitudinal_sequential_prediction_data_dict[\"test_set\"][\"eye_list\"]\n",
    "    test_label_list = longitudinal_sequential_prediction_data_dict[\"test_set\"][\"label_list\"]\n",
    "    max_len_test_set = count_max_len(test_label_list)\n",
    "\n",
    "    test_eye = np.zeros(shape=(len(test_eye_list), max_len_test_set, int(resizing*scale), int(resizing*scale), channel))\n",
    "    test_label = np.zeros(shape=(len(test_label_list), max_len_test_set))\n",
    "    \n",
    "    \n",
    "    print(\"processing test set...\")\n",
    "    progbar = tf.keras.utils.Progbar(len(test_eye_list))\n",
    "    \n",
    "    for list_idx, (eyes, labels) in enumerate(zip(test_eye_list, test_label_list)):\n",
    "\n",
    "        for eye_idx, eye in enumerate(eyes):\n",
    "            eye_filename = data_root_path + eye.split(\" \")[0] + \"/\" + eye\n",
    "            eye_img = parse_image(eye_filename, resizing=resizing, scale=scale, augmenter=None)\n",
    "            test_eye[list_idx, eye_idx, :, :, :] = eye_img\n",
    "        \n",
    "        test_label[list_idx, :len(labels)] = labels\n",
    "        \n",
    "        progbar.add(1)\n",
    "        \n",
    "    print(\"saving test data...\")\n",
    "    np.save(os.path.join(output_path, \"test_eye.npy\"), test_eye)\n",
    "    np.save(os.path.join(output_path, \"test_label.npy\"), test_label)\n",
    "    \n",
    "    test_dataset_tf = tf.data.Dataset.from_tensor_slices((test_eye, test_label))\n",
    "    test_dataset_tf_element_spec = test_dataset_tf.element_spec\n",
    "    test_dataset_tf_path = os.path.join(output_path, \"test_dataset_tf\")\n",
    "    test_dataset_tf_element_spec_path = os.path.join(output_path, \"test_dataset_tf_element_spec.pkl\")\n",
    "    tf.data.experimental.save(test_dataset_tf, test_dataset_tf_path)\n",
    "    save_data(test_dataset_tf_element_spec_path, test_dataset_tf_element_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_tf_per_length_data_set(data_root_path, output_path, longitudinal_sequential_prediction_data_dict, resizing, scale, channel):\n",
    "    \n",
    "    per_legnth_test_dict = longitudinal_sequential_prediction_data_dict[\"per_length_test_set\"]\n",
    "    \n",
    "    print(\"processing per length test set...\")\n",
    "    per_length_test_set_dict = dict()\n",
    "    \n",
    "    for length, length_dict in per_legnth_test_dict.items():\n",
    "        \n",
    "        print(\"processing length {}\".format(length))\n",
    "        \n",
    "        this_length_test_eye_list = length_dict[\"eye_list\"]\n",
    "        this_length_test_label_list = length_dict[\"label_list\"]\n",
    "        \n",
    "        this_length_test_eye = np.zeros(shape=(len(this_length_test_eye_list), length, int(resizing*scale), int(resizing*scale), channel))\n",
    "        test_length_test_label = np.zeros(shape=(len(this_length_test_label_list), length))\n",
    "        \n",
    "        for list_idx, (eyes, labels) in enumerate(zip(this_length_test_eye_list, this_length_test_label_list)):\n",
    "            \n",
    "            for eye_idx, eye in enumerate(eyes):\n",
    "                eye_filename = data_root_path + eye.split(\" \")[0] + \"/\" + eye\n",
    "                eye_img = parse_image(eye_filename, resizing=resizing, scale=scale, augmenter=None)\n",
    "                this_length_test_eye[list_idx, eye_idx, :, :, :] = eye_img\n",
    "        \n",
    "            test_length_test_label[list_idx, :len(labels)] = labels\n",
    "        \n",
    "        print(\"saving length {} test data...\".format(length))\n",
    "        this_length_test_dataset_tf = tf.data.Dataset.from_tensor_slices((this_length_test_eye, test_length_test_label))\n",
    "        file_path = os.path.join(output_path, \"length_{}_test_dataset_tf\".format(length))\n",
    "        tf.data.experimental.save(this_length_test_dataset_tf, file_path)\n",
    "        this_length_test_dataset_elem_spec = this_length_test_dataset_tf.element_spec\n",
    "        this_length_test_dataset_elem_spec_path = os.path.join(output_path, \"length_{}_test_dataset_element_spec.pkl\".format(length))\n",
    "        save_data(this_length_test_dataset_elem_spec_path, this_length_test_dataset_elem_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing training data of 1th split ...\n",
      "   8/1093 [..............................] - ETA: 5:47"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-10c13f61585d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m build_train_tf_data_set(\"/home/jl5307/current_research/AMD_prediction/img_data/img_files/\", \n\u001b[1;32m      2\u001b[0m                              \u001b[0;34m\"/home/jl5307/current_research/AMD_prediction/img_data/numpy_data/\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m                              longitudinal_sequential_prediction_timedelta5_data_dict, 256, 0.875, 3, divide=4, augment=False)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-6-3bc4a35aeff4>\u001b[0m in \u001b[0;36mbuild_train_tf_data_set\u001b[0;34m(data_root_path, output_path, longitudinal_sequential_prediction_data_dict, resizing, scale, channel, divide, augment)\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0meye_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meye\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meyes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m                 \u001b[0meye_filename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_root_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0meye\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0meye\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m                 \u001b[0meye_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparse_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meye_filename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresizing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresizing\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maugmenter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maugmeter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m                 \u001b[0mthis_split_train_eye\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlist_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meye_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meye_img\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-72971355a1e3>\u001b[0m in \u001b[0;36mparse_image\u001b[0;34m(filename, resizing, scale, augmenter)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m     \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode_jpeg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m     \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/current_research/virtualenvs/python3-workspace/lib/python3.6/site-packages/tensorflow/python/ops/gen_image_ops.py\u001b[0m in \u001b[0;36mdecode_jpeg\u001b[0;34m(contents, channels, ratio, fancy_upscaling, try_recover_truncated, acceptable_fraction, dct_method, name)\u001b[0m\n\u001b[1;32m   1171\u001b[0m           \u001b[0mtry_recover_truncated\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtry_recover_truncated\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1172\u001b[0m           \u001b[0macceptable_fraction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0macceptable_fraction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdct_method\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdct_method\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1173\u001b[0;31m           name=name, ctx=_ctx)\n\u001b[0m\u001b[1;32m   1174\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_SymbolicException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1175\u001b[0m       \u001b[0;32mpass\u001b[0m  \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/current_research/virtualenvs/python3-workspace/lib/python3.6/site-packages/tensorflow/python/ops/gen_image_ops.py\u001b[0m in \u001b[0;36mdecode_jpeg_eager_fallback\u001b[0;34m(contents, channels, ratio, fancy_upscaling, try_recover_truncated, acceptable_fraction, dct_method, name, ctx)\u001b[0m\n\u001b[1;32m   1241\u001b[0m   \"acceptable_fraction\", acceptable_fraction, \"dct_method\", dct_method)\n\u001b[1;32m   1242\u001b[0m   _result = _execute.execute(b\"DecodeJpeg\", 1, inputs=_inputs_flat,\n\u001b[0;32m-> 1243\u001b[0;31m                              attrs=_attrs, ctx=ctx, name=name)\n\u001b[0m\u001b[1;32m   1244\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0m_execute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmust_record_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1245\u001b[0m     _execute.record_gradient(\n",
      "\u001b[0;32m~/current_research/virtualenvs/python3-workspace/lib/python3.6/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "build_train_tf_data_set(\"/home/jl5307/current_research/AMD_prediction/img_data/img_files/\", \n",
    "                             \"/home/jl5307/current_research/AMD_prediction/img_data/numpy_data/\", \n",
    "                             longitudinal_sequential_prediction_timedelta5_data_dict, 256, 0.875, 3, divide=4, augment=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing validation set...\n",
      "936/936 [==============================] - 270s 288ms/step\n",
      "saving validation data...\n"
     ]
    }
   ],
   "source": [
    "build_validation_tf_data_set(\"/home/jl5307/current_research/AMD_prediction/img_data/img_files/\", \n",
    "                             \"/home/jl5307/current_research/AMD_prediction/img_data/numpy_data/\", \n",
    "                             longitudinal_sequential_prediction_timedelta5_data_dict, 256, 0.875, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing test set...\n",
      "952/952 [==============================] - 273s 287ms/step\n",
      "saving test data...\n"
     ]
    }
   ],
   "source": [
    "build_test_tf_data_set(\"/home/jl5307/current_research/AMD_prediction/img_data/img_files/\", \n",
    "                             \"/home/jl5307/current_research/AMD_prediction/img_data/numpy_data/\", \n",
    "                             longitudinal_sequential_prediction_timedelta5_data_dict, 256, 0.875, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing per length test set...\n",
      "processing length 1\n",
      "saving length 1 test data...\n",
      "processing length 2\n",
      "saving length 2 test data...\n",
      "processing length 3\n",
      "saving length 3 test data...\n",
      "processing length 4\n",
      "saving length 4 test data...\n",
      "processing length 5\n",
      "saving length 5 test data...\n",
      "processing length 6\n",
      "saving length 6 test data...\n",
      "processing length 7\n",
      "saving length 7 test data...\n",
      "processing length 8\n",
      "saving length 8 test data...\n",
      "processing length 9\n",
      "saving length 9 test data...\n",
      "processing length 10\n",
      "saving length 10 test data...\n",
      "processing length 11\n",
      "saving length 11 test data...\n",
      "processing length 12\n",
      "saving length 12 test data...\n"
     ]
    }
   ],
   "source": [
    "build_tf_per_length_data_set(\"/home/jl5307/current_research/AMD_prediction/img_data/img_files/\",\n",
    "                              \"/home/jl5307/current_research/AMD_prediction/img_data/numpy_data/\", longitudinal_sequential_prediction_timedelta5_data_dict, 256, 0.875, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_eye = np.load(\"/home/jl5307/current_research/AMD_prediction/img_data/numpy_data/longitudinal_sequential_prediction_timedelta2/train_eye.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label = np.load(\"/home/jl5307/current_research/AMD_prediction/img_data/numpy_data/longitudinal_sequential_prediction_timedelta2/train_label.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((train_eye, train_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_eye = np.load(\"/home/jl5307/current_research/AMD_prediction/img_data/numpy_data/longitudinal_sequential_prediction_timedelta2/validation_eye.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_label = np.load(\"/home/jl5307/current_research/AMD_prediction/img_data/numpy_data/longitudinal_sequential_prediction_timedelta2/validation_label.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_dataset = tf.data.Dataset.from_tensor_slices((validation_eye, validation_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1160"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(validation_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eye = np.load(\"/home/jl5307/current_research/AMD_prediction/img_data/numpy_data/longitudinal_sequential_prediction_timedelta2/test_eye.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_label = np.load(\"/home/jl5307/current_research/AMD_prediction/img_data/numpy_data/longitudinal_sequential_prediction_timedelta2/test_label.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = tf.data.Dataset.from_tensor_slices((test_eye, test_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset_element_spec = test_dataset.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_data(\"/home/jl5307/current_research/AMD_prediction/img_data/numpy_data/test_dataset_element_spec.pkl\", test_dataset_element_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.data.experimental.save(test_dataset, \"/home/jl5307/current_research/AMD_prediction/img_data/numpy_data/test_dataset_tf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "td = load_data(\"/home/jl5307/current_research/AMD_prediction/img_data/numpy_data/per_length_test_set_dict.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = td[4][\"eye\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_eye = np.load(\"/home/jl5307/current_research/AMD_prediction/img_data/numpy_data/longitudinal_sequential_prediction_timedelta2/dataset_npy/validation_dataset_npy/validation_eye.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_label = np.load(\"/home/jl5307/current_research/AMD_prediction/img_data/numpy_data/longitudinal_sequential_prediction_timedelta2/dataset_npy/validation_dataset_npy/validation_label.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_label[15,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(range(1, 12))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3-workspace",
   "language": "python",
   "name": "python3-workspace"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
